{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import keras \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# taking data from pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the location of the data was as below when i took into my laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"/home/swamikedari/Arificial Intelligence/dataset-20220716T053416Z-001/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i was getting errors in due to the file name so i changed it to 0 and 1 in my laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0 ,1]:\n",
    "    imglist=os.listdir(\"/home/swamikedari/Arificial Intelligence/dataset-20220716T053416Z-001/dataset/\"+str(i))\n",
    "    for filename in imglist:\n",
    "        image=cv2.imread(\"/home/swamikedari/Arificial Intelligence/dataset-20220716T053416Z-001/dataset/\"+str(i)+\"/\"+str(filename))\n",
    "        try:\n",
    "            a=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "            image=cv2.resize(a,(100,100))\n",
    "            img.append(image)\n",
    "            labels.append(i)\n",
    "        except:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376, 100, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div(x):\n",
    "    x=x/255\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=list(map(div,image))\n",
    "image=np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting the data into training and testing features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d=train_test_split(img,labels,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 100, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a.reshape(a.shape[0],a.shape[1],a.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 100, 100, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.reshape(b.shape[0],b.shape[1],b.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 100, 100, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg=ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.2,shear_range=0.1,rotation_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.fit(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches=dg.flow(a,c,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 100, 100, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# increasing the number of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=to_categorical(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D,Dense,Conv2D,Flatten,Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# specify the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 15:27:14.105292: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-07-16 15:27:14.105318: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pop-os): /proc/driver/nvidia/version does not exist\n",
      "2022-07-16 15:27:14.105626: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(128,(3,3),activation=\"relu\",input_shape=(100,100,1)))\n",
    "model.add(Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model.add(Conv2D(100,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(750,activation=\"relu\"))\n",
    "model.add(Dense(350,activation=\"relu\"))\n",
    "model.add(Dense(350,activation=\"relu\"))\n",
    "model.add(Dense(2,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swamikedari/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(lr=0.0001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59482/4024386068.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(dg.flow(a,c,batch_size=5),epochs=20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 47s 209ms/step - loss: 0.7865 - accuracy: 0.5755\n",
      "Epoch 2/20\n",
      "220/220 [==============================] - 49s 224ms/step - loss: 0.5838 - accuracy: 0.6900\n",
      "Epoch 3/20\n",
      "220/220 [==============================] - 49s 225ms/step - loss: 0.4231 - accuracy: 0.8055\n",
      "Epoch 4/20\n",
      "220/220 [==============================] - 50s 226ms/step - loss: 0.3071 - accuracy: 0.8745\n",
      "Epoch 5/20\n",
      "220/220 [==============================] - 50s 226ms/step - loss: 0.3150 - accuracy: 0.8782\n",
      "Epoch 6/20\n",
      "220/220 [==============================] - 50s 226ms/step - loss: 0.2350 - accuracy: 0.9127\n",
      "Epoch 7/20\n",
      "220/220 [==============================] - 50s 227ms/step - loss: 0.1907 - accuracy: 0.9200\n",
      "Epoch 8/20\n",
      "220/220 [==============================] - 51s 230ms/step - loss: 0.1488 - accuracy: 0.9455\n",
      "Epoch 9/20\n",
      "220/220 [==============================] - 50s 227ms/step - loss: 0.1401 - accuracy: 0.9500\n",
      "Epoch 10/20\n",
      "220/220 [==============================] - 50s 229ms/step - loss: 0.1536 - accuracy: 0.9500\n",
      "Epoch 11/20\n",
      "220/220 [==============================] - 55s 248ms/step - loss: 0.1155 - accuracy: 0.9564\n",
      "Epoch 12/20\n",
      "220/220 [==============================] - 55s 248ms/step - loss: 0.1182 - accuracy: 0.9573\n",
      "Epoch 13/20\n",
      "220/220 [==============================] - 53s 241ms/step - loss: 0.1220 - accuracy: 0.9591\n",
      "Epoch 14/20\n",
      "220/220 [==============================] - 54s 245ms/step - loss: 0.0906 - accuracy: 0.9727\n",
      "Epoch 15/20\n",
      "220/220 [==============================] - 57s 259ms/step - loss: 0.0788 - accuracy: 0.9727\n",
      "Epoch 16/20\n",
      "220/220 [==============================] - 48s 220ms/step - loss: 0.0878 - accuracy: 0.9627\n",
      "Epoch 17/20\n",
      "220/220 [==============================] - 53s 239ms/step - loss: 0.0695 - accuracy: 0.9736\n",
      "Epoch 18/20\n",
      "220/220 [==============================] - 56s 256ms/step - loss: 0.1055 - accuracy: 0.9627\n",
      "Epoch 19/20\n",
      "220/220 [==============================] - 59s 270ms/step - loss: 0.0596 - accuracy: 0.9773\n",
      "Epoch 20/20\n",
      "220/220 [==============================] - 49s 222ms/step - loss: 0.0806 - accuracy: 0.9745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2febc512d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(dg.flow(a,c,batch_size=5),epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 100, 100, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# taking pictures from the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classtype(x):\n",
    "    if x==0: return \"with      mask\"\n",
    "    elif x==1 : return \"with     out       mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp=cv2.VideoCapture(0)\n",
    "cp.set(3,640)\n",
    "cp.set(4,480)\n",
    "cp.set(10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier(\"/home/swamikedari/Arificial Intelligence/haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "while True:\n",
    "    success,imgcam=cp.read()\n",
    "    j=np.array(imgcam)\n",
    "    j=cv2.resize(j,(100,100))\n",
    "    j=cv2.cvtColor(j,cv2.COLOR_BGR2GRAY)\n",
    "    face=face_cascade.detectMultiScale(j,1.1,1)\n",
    "    for(x,y,w,h) in face:\n",
    "        cv2.rectangle(j,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "        j=face[x:x+w,y:y+h]\n",
    "    j=div(j)\n",
    "    #cv2.imshow(\"processed\",j)\n",
    "    j=j.reshape(1,100,100,1)\n",
    "    cv2.putText(imgcam,(\"class  : \"),(20,35),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(imgcam,(\"status  :\"),(20,80),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "    pred=model.predict(j)\n",
    "    cl=np.argmax(pred,axis=1)\n",
    "    probabilityValue=np.amax(pred)\n",
    "    if probabilityValue>0.9:\n",
    "        cv2.putText(imgcam,str(cl),(200,35),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "        cv2.putText(imgcam,str(classtype(cl)),(200,80),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow(\"result\",imgcam)\n",
    "    if cv2.waitKey(1)==113:\n",
    "        cv2.destroyAllWindows()\n",
    "        cp.release()\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65228164"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilityValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
